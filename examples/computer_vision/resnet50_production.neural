# ============================================================================
# Production-Ready ResNet-50 for Image Classification
# ============================================================================
# This example demonstrates a complete ResNet-50 implementation ready for
# production use with real-world computer vision tasks.
#
# Architecture: ResNet-50 with bottleneck blocks
# Task: Image classification (ImageNet, custom datasets)
# Backends: TensorFlow, PyTorch, ONNX
# Features:
#   - Bottleneck residual blocks for efficiency
#   - Batch normalization for faster training
#   - Data augmentation integration
#   - Mixed precision training support
#   - Transfer learning capabilities
# ============================================================================

# --------------------------------------------------------------------
# MACRO DEFINITIONS - ResNet-50 Building Blocks
# --------------------------------------------------------------------

define ConvBlock(filters, kernel_size, strides) {
  Conv2D(
    filters=$filters,
    kernel_size=$kernel_size,
    strides=$strides,
    padding="same",
    use_bias=False
  )
  BatchNormalization(momentum=0.9, epsilon=1e-5)
  Activation("relu")
}

define BottleneckBlock(filters, stride) {
  Conv2D(filters=$filters, kernel_size=(1, 1), strides=(1, 1), padding="same", use_bias=False)
  BatchNormalization(momentum=0.9, epsilon=1e-5)
  Activation("relu")
  
  Conv2D(filters=$filters, kernel_size=(3, 3), strides=$stride, padding="same", use_bias=False)
  BatchNormalization(momentum=0.9, epsilon=1e-5)
  Activation("relu")
  
  Conv2D(filters=$filters*4, kernel_size=(1, 1), strides=(1, 1), padding="same", use_bias=False)
  BatchNormalization(momentum=0.9, epsilon=1e-5)
}

define IdentityBlock(filters) {
  Conv2D(filters=$filters, kernel_size=(1, 1), strides=(1, 1), padding="same", use_bias=False)
  BatchNormalization(momentum=0.9, epsilon=1e-5)
  Activation("relu")
  
  Conv2D(filters=$filters, kernel_size=(3, 3), strides=(1, 1), padding="same", use_bias=False)
  BatchNormalization(momentum=0.9, epsilon=1e-5)
  Activation("relu")
  
  Conv2D(filters=$filters*4, kernel_size=(1, 1), strides=(1, 1), padding="same", use_bias=False)
  BatchNormalization(momentum=0.9, epsilon=1e-5)
  
  Add()
  Activation("relu")
}

# --------------------------------------------------------------------
# MAIN NETWORK DEFINITION - ResNet-50
# --------------------------------------------------------------------

network ResNet50 {
  input: (224, 224, 3)
  
  layers:
    Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding="same", use_bias=False)
    BatchNormalization(momentum=0.9, epsilon=1e-5)
    Activation("relu")
    MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding="same")
    
    # Stage 2: 64 filters
    IdentityBlock(filters=64)
    IdentityBlock(filters=64)
    IdentityBlock(filters=64)
    
    # Stage 3: 128 filters
    IdentityBlock(filters=128)
    IdentityBlock(filters=128)
    IdentityBlock(filters=128)
    IdentityBlock(filters=128)
    
    # Stage 4: 256 filters
    IdentityBlock(filters=256)
    IdentityBlock(filters=256)
    IdentityBlock(filters=256)
    IdentityBlock(filters=256)
    IdentityBlock(filters=256)
    IdentityBlock(filters=256)
    
    # Stage 5: 512 filters
    IdentityBlock(filters=512)
    IdentityBlock(filters=512)
    IdentityBlock(filters=512)
    
    GlobalAveragePooling2D()
    Dropout(rate=0.2)
    Output(units=1000, activation="softmax")
  
  loss: "sparse_categorical_crossentropy"
  optimizer: SGD(learning_rate=0.1, momentum=0.9, nesterov=True)
  metrics: ["accuracy", "top_k_accuracy"]
  
  train {
    epochs: 90
    batch_size: 32
    validation_split: 0.1
    gradient_clip: 5.0
  }
}
