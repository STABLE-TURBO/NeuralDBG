# ============================================================================
# Transformer Hyperparameter Optimization with Optuna
# ============================================================================
# This example demonstrates comprehensive HPO for transformer architectures
# using Neural DSL's integrated Optuna support.
#
# Features:
#   - Multi-objective optimization (accuracy, speed, model size)
#   - Architecture search (layers, heads, dimensions)
#   - Training hyperparameters (learning rate, batch size, dropout)
#   - Early stopping and pruning
#   - Cross-backend support (TensorFlow, PyTorch)
# ============================================================================

# --------------------------------------------------------------------
# MACRO DEFINITIONS with HPO Parameters
# --------------------------------------------------------------------

define OptimizedAttentionBlock(num_heads, d_model, dropout) {
  # Multi-head attention with optimizable parameters
  Dense(units=$d_model, activation="linear")  # Query
  Dense(units=$d_model, activation="linear")  # Key  
  Dense(units=$d_model, activation="linear")  # Value
  
  Dropout(rate=$dropout)
  Dense(units=$d_model, activation="linear")
  Dropout(rate=$dropout)
}

define OptimizedFeedForward(d_model, d_ff, dropout) {
  # Feed-forward network with HPO
  Dense(units=$d_ff, activation="gelu")
  Dropout(rate=$dropout)
  Dense(units=$d_model, activation="linear")
  Dropout(rate=$dropout)
}

define OptimizedTransformerLayer(num_heads, d_model, d_ff, dropout) {
  # Complete transformer layer with residuals
  OptimizedAttentionBlock(
    num_heads=$num_heads,
    d_model=$d_model,
    dropout=$dropout
  )
  Add()
  LayerNormalization()
  
  OptimizedFeedForward(
    d_model=$d_model,
    d_ff=$d_ff,
    dropout=$dropout
  )
  Add()
  LayerNormalization()
}

# --------------------------------------------------------------------
# MAIN NETWORK with HPO Integration
# --------------------------------------------------------------------

network TransformerWithHPO {
  # Input specification
  input: (512,)  # Sequence length
  
  layers:
    # Embedding layer
    # Optimize embedding dimension
    Embedding(
      input_dim=32000,
      output_dim=HPO(categorical(256, 512, 768, 1024)),
      mask_zero=True
    )
    
    # Positional encoding dropout
    Dropout(rate=HPO(range(0.0, 0.3, step=0.05)))
    
    # Transformer layers
    # Optimize number of layers (model depth)
    # Layer 1
    OptimizedTransformerLayer(
      num_heads=HPO(categorical(4, 8, 12, 16)),
      d_model=HPO(categorical(256, 512, 768, 1024)),
      d_ff=HPO(categorical(1024, 2048, 3072, 4096)),
      dropout=HPO(range(0.1, 0.3, step=0.05))
    )
    
    # Layer 2
    OptimizedTransformerLayer(
      num_heads=HPO(categorical(4, 8, 12, 16)),
      d_model=HPO(categorical(256, 512, 768, 1024)),
      d_ff=HPO(categorical(1024, 2048, 3072, 4096)),
      dropout=HPO(range(0.1, 0.3, step=0.05))
    )
    
    # Layer 3
    OptimizedTransformerLayer(
      num_heads=HPO(categorical(4, 8, 12, 16)),
      d_model=HPO(categorical(256, 512, 768, 1024)),
      d_ff=HPO(categorical(1024, 2048, 3072, 4096)),
      dropout=HPO(range(0.1, 0.3, step=0.05))
    )
    
    # Layer 4
    OptimizedTransformerLayer(
      num_heads=HPO(categorical(4, 8, 12, 16)),
      d_model=HPO(categorical(256, 512, 768, 1024)),
      d_ff=HPO(categorical(1024, 2048, 3072, 4096)),
      dropout=HPO(range(0.1, 0.3, step=0.05))
    )
    
    # Layer 5
    OptimizedTransformerLayer(
      num_heads=HPO(categorical(4, 8, 12, 16)),
      d_model=HPO(categorical(256, 512, 768, 1024)),
      d_ff=HPO(categorical(1024, 2048, 3072, 4096)),
      dropout=HPO(range(0.1, 0.3, step=0.05))
    )
    
    # Layer 6
    OptimizedTransformerLayer(
      num_heads=HPO(categorical(4, 8, 12, 16)),
      d_model=HPO(categorical(256, 512, 768, 1024)),
      d_ff=HPO(categorical(1024, 2048, 3072, 4096)),
      dropout=HPO(range(0.1, 0.3, step=0.05))
    )
    
    # Output layers
    GlobalAveragePooling1D()
    
    # Optional dense layer before output
    Dense(
      units=HPO(categorical(256, 512, 1024)),
      activation="relu"
    )
    Dropout(rate=HPO(range(0.2, 0.5, step=0.1)))
    
    # Output layer for classification
    Output(units=10, activation="softmax")
  
  # Loss function
  loss: "sparse_categorical_crossentropy"
  
  # Optimizer with HPO
  optimizer: Adam(
    learning_rate=HPO(log_range(1e-5, 1e-2)),
    beta_1=HPO(range(0.85, 0.95, step=0.02)),
    beta_2=HPO(range(0.95, 0.999, step=0.01)),
    epsilon=1e-8
  )
  
  # Metrics
  metrics: ["accuracy", "sparse_categorical_crossentropy"]
  
  # Training configuration with HPO
  train {
    # Optimize training epochs
    epochs: HPO(categorical(10, 20, 30, 40))
    
    # Optimize batch size
    batch_size: HPO(categorical(16, 32, 64, 128))
    
    # Validation split
    validation_split: 0.15
    
    # Gradient clipping
    gradient_clip: HPO(range(0.5, 2.0, step=0.5))
    
    # Early stopping patience
    early_stopping: HPO(categorical(5, 10, 15))
  }
}

# ============================================================================
# HPO EXECUTION EXAMPLES
# ============================================================================
#
# 1. Basic HPO with Optuna (Python)
# ----------------------------------
#
# from neural.hpo import optimize_and_return
#
# # Run hyperparameter optimization
# best_params = optimize_and_return(
#     config="examples/hpo_examples/transformer_hpo_complete.neural",
#     n_trials=50,
#     dataset_name='IMDB',  # Or custom dataset
#     backend='pytorch',
#     device='cuda',
#     
#     # Optuna settings
#     sampler='tpe',  # Tree-structured Parzen Estimator
#     pruner='median',  # Median stopping rule
#     
#     # Objective
#     direction='maximize',
#     metric='accuracy',
#     
#     # Parallel execution
#     n_jobs=4  # Run 4 trials in parallel
# )
#
# print("Best hyperparameters:", best_params)
# # Output:
# # {
# #   'embedding_dim': 768,
# #   'num_heads': 12,
# #   'd_ff': 3072,
# #   'dropout': 0.15,
# #   'learning_rate': 0.0003,
# #   'batch_size': 64,
# #   'epochs': 30
# # }
#
# ============================================================================
# 2. Multi-Objective Optimization
# --------------------------------
#
# from neural.hpo import MultiObjectiveOptimizer
#
# optimizer = MultiObjectiveOptimizer(
#     config="examples/hpo_examples/transformer_hpo_complete.neural",
#     objectives=[
#         ('accuracy', 'maximize'),
#         ('training_time', 'minimize'),
#         ('model_size', 'minimize')
#     ]
# )
#
# # Run multi-objective search
# pareto_front = optimizer.optimize(
#     n_trials=100,
#     dataset_name='IMDB',
#     backend='pytorch'
# )
#
# # Get Pareto-optimal solutions
# for solution in pareto_front:
#     print(f"Accuracy: {solution['accuracy']:.4f}, "
#           f"Time: {solution['training_time']:.2f}s, "
#           f"Size: {solution['model_size']:.2f}MB")
#
# ============================================================================
# 3. Advanced HPO with Visualization
# -----------------------------------
#
# from neural.hpo import optimize_and_return
# from neural.hpo.visualization import (
#     plot_optimization_history,
#     plot_param_importance,
#     plot_parallel_coordinates,
#     create_optimization_report
# )
#
# # Run optimization with study tracking
# study = optimize_and_return(
#     config="examples/hpo_examples/transformer_hpo_complete.neural",
#     n_trials=50,
#     dataset_name='IMDB',
#     backend='pytorch',
#     return_study=True  # Return full Optuna study
# )
#
# # Visualize results
# plot_optimization_history(study, save_path='opt_history.png')
# plot_param_importance(study, save_path='param_importance.png')
# plot_parallel_coordinates(study, save_path='parallel_coords.png')
#
# # Generate HTML report
# create_optimization_report(
#     study,
#     output_path='hpo_report.html',
#     include_plots=True
# )
#
# ============================================================================
# 4. Distributed HPO with Ray Tune
# ---------------------------------
#
# from neural.hpo import DistributedHPO
#
# # Initialize distributed optimizer
# distributed_hpo = DistributedHPO(
#     config="examples/hpo_examples/transformer_hpo_complete.neural",
#     backend='pytorch',
#     num_gpus_per_trial=1,
#     num_cpus_per_trial=2
# )
#
# # Run distributed search
# results = distributed_hpo.run(
#     n_trials=100,
#     max_concurrent_trials=8,  # Run 8 trials simultaneously
#     dataset_name='IMDB',
#     search_algorithm='bayesopt',  # Bayesian optimization
#     scheduler='asha'  # Async Successive Halving
# )
#
# # Get best configuration
# best_config = results.get_best_config(metric='accuracy', mode='max')
# print("Best configuration:", best_config)
#
# ============================================================================
# 5. HPO with Custom Search Space
# --------------------------------
#
# from neural.hpo import optimize_and_return
#
# # Define custom search space
# search_space = {
#     'embedding_dim': [256, 512, 768, 1024],
#     'num_layers': [4, 6, 8, 12],
#     'num_heads': [4, 8, 12, 16],
#     'd_ff_multiplier': [2, 3, 4],  # d_ff = d_model * multiplier
#     'dropout': (0.0, 0.3),
#     'learning_rate': (1e-5, 1e-2, 'log'),
#     'batch_size': [16, 32, 64, 128],
#     'warmup_steps': [500, 1000, 2000],
#     'weight_decay': (0.0, 0.1)
# }
#
# best_params = optimize_and_return(
#     config="examples/hpo_examples/transformer_hpo_complete.neural",
#     n_trials=50,
#     search_space=search_space,
#     dataset_name='IMDB',
#     backend='pytorch'
# )
#
# ============================================================================
# 6. Transfer Learning with HPO
# ------------------------------
#
# # Fine-tune pre-trained transformer with HPO
# best_params = optimize_and_return(
#     config="examples/hpo_examples/transformer_hpo_complete.neural",
#     n_trials=30,
#     dataset_name='CustomDataset',
#     backend='pytorch',
#     
#     # Transfer learning settings
#     pretrained_weights='path/to/pretrained_model.pth',
#     freeze_embeddings=True,
#     freeze_layers=[0, 1, 2],  # Freeze first 3 layers
#     
#     # Fine-tuning HPO
#     hpo_scope=['learning_rate', 'dropout', 'batch_size'],
#     learning_rate_range=(1e-6, 1e-4)  # Lower for fine-tuning
# )
#
# ============================================================================
# CLI USAGE
# ============================================================================
#
# Run HPO from command line:
#
# # Basic HPO
# neural hpo examples/hpo_examples/transformer_hpo_complete.neural \
#   --n-trials 50 \
#   --dataset IMDB \
#   --backend pytorch \
#   --device cuda
#
# # Multi-objective HPO
# neural hpo examples/hpo_examples/transformer_hpo_complete.neural \
#   --n-trials 100 \
#   --objectives accuracy:maximize training_time:minimize \
#   --backend pytorch
#
# # Distributed HPO
# neural hpo examples/hpo_examples/transformer_hpo_complete.neural \
#   --n-trials 200 \
#   --distributed ray \
#   --num-workers 8 \
#   --backend pytorch
#
# # With visualization
# neural hpo examples/hpo_examples/transformer_hpo_complete.neural \
#   --n-trials 50 \
#   --visualize \
#   --output-dir hpo_results \
#   --backend pytorch
#
# ============================================================================
# BEST PRACTICES
# ============================================================================
#
# 1. Search Space Design:
#    - Start with wide ranges, narrow based on results
#    - Use log scale for learning rates and regularization
#    - Consider architectural constraints (e.g., d_model % num_heads == 0)
#
# 2. Number of Trials:
#    - Minimum: 20-30 trials for basic search
#    - Recommended: 50-100 trials for thorough search
#    - Extensive: 200+ trials for production models
#
# 3. Pruning Strategy:
#    - Use early stopping to avoid wasting compute
#    - Median pruner works well for most cases
#    - ASHA for distributed/parallel search
#
# 4. Validation:
#    - Use holdout validation set (not test set)
#    - Cross-validation for small datasets
#    - Monitor overfitting (train vs. val metrics)
#
# 5. Resource Management:
#    - Limit max epochs per trial
#    - Use gradient accumulation for large models
#    - Distribute across multiple GPUs when possible
#
# 6. Result Analysis:
#    - Check parameter importance plots
#    - Look for parameter correlations
#    - Validate best config on test set
#
# ============================================================================
