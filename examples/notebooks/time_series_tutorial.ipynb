{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting with Neural DSL\n",
    "\n",
    "This tutorial demonstrates building time series prediction models using Neural DSL.\n",
    "\n",
    "## Overview\n",
    "- Build CNN-LSTM hybrid for time series\n",
    "- Handle sequential data\n",
    "- Forecast future values\n",
    "- Evaluate forecasting accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from neural.parser.parser import create_parser, ModelTransformer\n",
    "from neural.code_generation.code_generator import generate_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Time Series Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsl_code = \"\"\"\n",
    "network TimeSeriesPredictor {\n",
    "  input: (None, 100, 1)\n",
    "  \n",
    "  layers:\n",
    "    Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding=\"same\")\n",
    "    BatchNormalization()\n",
    "    Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding=\"same\")\n",
    "    BatchNormalization()\n",
    "    MaxPooling1D(pool_size=2)\n",
    "    Dropout(rate=0.2)\n",
    "    \n",
    "    LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "    LSTM(units=64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "    LSTM(units=32, dropout=0.2, recurrent_dropout=0.2)\n",
    "    \n",
    "    Dense(units=64, activation=\"relu\")\n",
    "    BatchNormalization()\n",
    "    Dropout(rate=0.3)\n",
    "    Dense(units=32, activation=\"relu\")\n",
    "    BatchNormalization()\n",
    "    Dropout(rate=0.3)\n",
    "    Output(units=1, activation=\"linear\")\n",
    "\n",
    "  loss: \"mse\"\n",
    "  optimizer: Adam(learning_rate=0.001)\n",
    "  metrics: [\"mae\", \"mse\"]\n",
    "\n",
    "  train {\n",
    "    epochs: 50\n",
    "    batch_size: 64\n",
    "    validation_split: 0.2\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open('time_series_predictor.neural', 'w') as f:\n",
    "    f.write(dsl_code)\n",
    "\n",
    "print(\"Time series model defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(n_points=10000):\n",
    "    \"\"\"Generate synthetic time series with trend, seasonality, and noise\"\"\"\n",
    "    t = np.arange(n_points)\n",
    "    \n",
    "    # Trend component\n",
    "    trend = 0.02 * t\n",
    "    \n",
    "    # Seasonal components\n",
    "    seasonal_1 = 10 * np.sin(2 * np.pi * t / 365)  # Yearly\n",
    "    seasonal_2 = 5 * np.sin(2 * np.pi * t / 30)    # Monthly\n",
    "    \n",
    "    # Noise\n",
    "    noise = np.random.randn(n_points) * 2\n",
    "    \n",
    "    # Combine components\n",
    "    series = trend + seasonal_1 + seasonal_2 + noise + 50\n",
    "    \n",
    "    return series\n",
    "\n",
    "# Generate data\n",
    "time_series = generate_time_series()\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(time_series[:1000])\n",
    "plt.title('Synthetic Time Series Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Generated time series with {len(time_series)} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length=100):\n",
    "    \"\"\"Create sequences for time series prediction\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(time_series.reshape(-1, 1))\n",
    "\n",
    "# Create sequences\n",
    "seq_length = 100\n",
    "X, y = create_sequences(scaled_data.flatten(), seq_length)\n",
    "\n",
    "# Reshape for model input\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Split into train and test\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Training sequences: {len(X_train)}\")\n",
    "print(f\"Test sequences: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!neural compile time_series_predictor.neural --backend tensorflow --output time_series_tf.py\n",
    "print(\"Model compiled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!neural visualize time_series_predictor.neural --format html\n",
    "print(\"Architecture visualization generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using CLI or generated code\n",
    "!neural run time_series_tf.py --backend tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions (pseudo-code)\n",
    "# predictions = model.predict(X_test)\n",
    "# predictions = scaler.inverse_transform(predictions.reshape(-1, 1))\n",
    "# y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "# \n",
    "# # Visualize predictions\n",
    "# plt.figure(figsize=(15, 6))\n",
    "# plt.plot(y_test_actual[:200], label='Actual', linewidth=2)\n",
    "# plt.plot(predictions[:200], label='Predicted', linewidth=2, alpha=0.7)\n",
    "# plt.title('Time Series Predictions vs Actual')\n",
    "# plt.xlabel('Time Step')\n",
    "# plt.ylabel('Value')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "print(\"Prediction visualization code ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# \n",
    "# mae = mean_absolute_error(y_test_actual, predictions)\n",
    "# mse = mean_squared_error(y_test_actual, predictions)\n",
    "# rmse = np.sqrt(mse)\n",
    "# r2 = r2_score(y_test_actual, predictions)\n",
    "# \n",
    "# print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "# print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "# print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "# print(f\"RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "print(\"Evaluation metrics template ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Step Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_multi_step(model, initial_sequence, n_steps, scaler):\n",
    "    \"\"\"Forecast multiple steps into the future\"\"\"\n",
    "    predictions = []\n",
    "    current_sequence = initial_sequence.copy()\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        # Predict next value\n",
    "        next_pred = model.predict(current_sequence.reshape(1, -1, 1))[0, 0]\n",
    "        predictions.append(next_pred)\n",
    "        \n",
    "        # Update sequence\n",
    "        current_sequence = np.roll(current_sequence, -1)\n",
    "        current_sequence[-1] = next_pred\n",
    "    \n",
    "    # Inverse transform\n",
    "    predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "    return predictions.flatten()\n",
    "\n",
    "# Example usage\n",
    "# initial_seq = X_test[0].flatten()\n",
    "# future_predictions = forecast_multi_step(model, initial_seq, 50, scaler)\n",
    "# \n",
    "# plt.figure(figsize=(15, 6))\n",
    "# plt.plot(range(len(initial_seq)), scaler.inverse_transform(initial_seq.reshape(-1, 1)), \n",
    "#          label='Historical', linewidth=2)\n",
    "# plt.plot(range(len(initial_seq), len(initial_seq) + len(future_predictions)), \n",
    "#          future_predictions, label='Forecast', linewidth=2, linestyle='--')\n",
    "# plt.title('Multi-Step Time Series Forecast')\n",
    "# plt.xlabel('Time Step')\n",
    "# plt.ylabel('Value')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "print(\"Multi-step forecasting function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals = y_test_actual - predictions\n",
    "# \n",
    "# fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "# \n",
    "# # Residual plot\n",
    "# axes[0, 0].scatter(predictions, residuals, alpha=0.5)\n",
    "# axes[0, 0].axhline(y=0, color='r', linestyle='--')\n",
    "# axes[0, 0].set_xlabel('Predicted Values')\n",
    "# axes[0, 0].set_ylabel('Residuals')\n",
    "# axes[0, 0].set_title('Residual Plot')\n",
    "# axes[0, 0].grid(True)\n",
    "# \n",
    "# # Residual histogram\n",
    "# axes[0, 1].hist(residuals, bins=50, edgecolor='black')\n",
    "# axes[0, 1].set_xlabel('Residual Value')\n",
    "# axes[0, 1].set_ylabel('Frequency')\n",
    "# axes[0, 1].set_title('Residual Distribution')\n",
    "# axes[0, 1].grid(True)\n",
    "# \n",
    "# # Q-Q plot\n",
    "# from scipy import stats\n",
    "# stats.probplot(residuals.flatten(), dist=\"norm\", plot=axes[1, 0])\n",
    "# axes[1, 0].set_title('Q-Q Plot')\n",
    "# axes[1, 0].grid(True)\n",
    "# \n",
    "# # Residuals over time\n",
    "# axes[1, 1].plot(residuals[:200])\n",
    "# axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
    "# axes[1, 1].set_xlabel('Time Step')\n",
    "# axes[1, 1].set_ylabel('Residual')\n",
    "# axes[1, 1].set_title('Residuals Over Time')\n",
    "# axes[1, 1].grid(True)\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "print(\"Residual analysis code ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!neural compile time_series_predictor.neural --backend tensorflow --hpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Applications\n",
    "\n",
    "This model can be applied to:\n",
    "- Stock price prediction\n",
    "- Energy consumption forecasting\n",
    "- Weather prediction\n",
    "- Sales forecasting\n",
    "- Traffic prediction\n",
    "- Anomaly detection in time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we:\n",
    "1. Built a CNN-LSTM hybrid for time series\n",
    "2. Generated and prepared sequential data\n",
    "3. Made single and multi-step forecasts\n",
    "4. Analyzed model performance and residuals\n",
    "\n",
    "## Next Steps\n",
    "- Try attention mechanisms for time series\n",
    "- Implement ARIMA/SARIMA for comparison\n",
    "- Use transformer models for long sequences\n",
    "- Build multivariate time series models\n",
    "- Implement anomaly detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
