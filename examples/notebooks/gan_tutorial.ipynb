{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GANs) with Neural DSL\n",
    "\n",
    "This tutorial demonstrates how to build and train GANs using Neural DSL.\n",
    "\n",
    "## Overview\n",
    "- Understand GAN architecture\n",
    "- Build Generator and Discriminator networks\n",
    "- Train adversarially\n",
    "- Generate new images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neural.parser.parser import create_parser, ModelTransformer\n",
    "from neural.code_generation.code_generator import generate_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding GANs\n",
    "\n",
    "A GAN consists of two neural networks:\n",
    "\n",
    "1. **Generator**: Creates fake samples from random noise\n",
    "2. **Discriminator**: Distinguishes between real and fake samples\n",
    "\n",
    "They compete in a minimax game:\n",
    "- Generator tries to fool the discriminator\n",
    "- Discriminator tries to correctly classify real vs fake\n",
    "\n",
    "Through this adversarial training, the generator learns to create realistic samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_code = \"\"\"\n",
    "network GANGenerator {\n",
    "  input: (None, 100)\n",
    "  \n",
    "  layers:\n",
    "    Dense(units=256, activation=\"relu\")\n",
    "    BatchNormalization()\n",
    "    Dense(units=512, activation=\"relu\")\n",
    "    BatchNormalization()\n",
    "    Dense(units=1024, activation=\"relu\")\n",
    "    BatchNormalization()\n",
    "    Dense(units=784, activation=\"tanh\")\n",
    "    Reshape(target_shape=(28, 28, 1))\n",
    "\n",
    "  loss: \"binary_crossentropy\"\n",
    "  optimizer: Adam(learning_rate=0.0002)\n",
    "\n",
    "  train {\n",
    "    epochs: 100\n",
    "    batch_size: 128\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open('gan_generator.neural', 'w') as f:\n",
    "    f.write(generator_code)\n",
    "\n",
    "print(\"Generator defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_code = \"\"\"\n",
    "network GANDiscriminator {\n",
    "  input: (None, 28, 28, 1)\n",
    "  \n",
    "  layers:\n",
    "    Flatten()\n",
    "    Dense(units=512, activation=\"relu\")\n",
    "    Dropout(rate=0.3)\n",
    "    Dense(units=256, activation=\"relu\")\n",
    "    Dropout(rate=0.3)\n",
    "    Output(units=1, activation=\"sigmoid\")\n",
    "\n",
    "  loss: \"binary_crossentropy\"\n",
    "  optimizer: Adam(learning_rate=0.0002)\n",
    "  metrics: [\"accuracy\"]\n",
    "\n",
    "  train {\n",
    "    epochs: 100\n",
    "    batch_size: 128\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open('gan_discriminator.neural', 'w') as f:\n",
    "    f.write(discriminator_code)\n",
    "\n",
    "print(\"Discriminator defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Both Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!neural compile gan_generator.neural --backend tensorflow --output gan_generator_tf.py\n",
    "!neural compile gan_discriminator.neural --backend tensorflow --output gan_discriminator_tf.py\n",
    "\n",
    "print(\"Both networks compiled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!neural visualize gan_generator.neural --format html\n",
    "!neural visualize gan_discriminator.neural --format html\n",
    "\n",
    "print(\"Visualizations generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    \n",
    "    # Load MNIST\n",
    "    (x_train, _), (_, _) = keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # Normalize to [-1, 1] for tanh activation\n",
    "    x_train = (x_train.astype('float32') - 127.5) / 127.5\n",
    "    x_train = np.expand_dims(x_train, axis=-1)\n",
    "    \n",
    "    print(f\"Training data shape: {x_train.shape}\")\n",
    "    print(f\"Value range: [{x_train.min():.2f}, {x_train.max():.2f}]\")\n",
    "    \n",
    "    # Display sample images\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(x_train[i].squeeze(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('Sample Training Images (MNIST)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"TensorFlow not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-code for GAN training\n",
    "# This would need to be adapted based on the generated code\n",
    "\n",
    "def train_gan(generator, discriminator, dataset, epochs=100, batch_size=128, latent_dim=100):\n",
    "    \"\"\"\n",
    "    Train GAN with alternating updates\n",
    "    \n",
    "    1. Train discriminator on real and fake data\n",
    "    2. Train generator to fool discriminator\n",
    "    \"\"\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Get real images\n",
    "        # idx = np.random.randint(0, dataset.shape[0], batch_size)\n",
    "        # real_images = dataset[idx]\n",
    "        \n",
    "        # Generate fake images\n",
    "        # noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        # fake_images = generator.predict(noise)\n",
    "        \n",
    "        # Train discriminator\n",
    "        # d_loss_real = discriminator.train_on_batch(real_images, np.ones((batch_size, 1)))\n",
    "        # d_loss_fake = discriminator.train_on_batch(fake_images, np.zeros((batch_size, 1)))\n",
    "        # d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # Train generator (via combined model)\n",
    "        # noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        # g_loss = combined_model.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "        \n",
    "        # Print progress\n",
    "        # if epoch % 100 == 0:\n",
    "        #     print(f\"Epoch {epoch}: [D loss: {d_loss[0]:.4f}, acc: {d_loss[1]:.2%}] [G loss: {g_loss:.4f}]\")\n",
    "        pass\n",
    "\n",
    "print(\"GAN training function template ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Images During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(generator, epoch, latent_dim=100):\n",
    "    \"\"\"\n",
    "    Generate images and save visualization\n",
    "    \"\"\"\n",
    "    # Generate images\n",
    "    # noise = np.random.normal(0, 1, (25, latent_dim))\n",
    "    # generated_images = generator.predict(noise)\n",
    "    \n",
    "    # Rescale to [0, 1]\n",
    "    # generated_images = (generated_images + 1) / 2.0\n",
    "    \n",
    "    # Plot\n",
    "    # fig = plt.figure(figsize=(10, 10))\n",
    "    # for i in range(25):\n",
    "    #     plt.subplot(5, 5, i + 1)\n",
    "    #     plt.imshow(generated_images[i].squeeze(), cmap='gray')\n",
    "    #     plt.axis('off')\n",
    "    # plt.suptitle(f'Generated Images at Epoch {epoch}')\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(f'generated_epoch_{epoch}.png')\n",
    "    # plt.close()\n",
    "    pass\n",
    "\n",
    "print(\"Image generation function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the generated models\n",
    "# exec(open('gan_generator_tf.py').read())\n",
    "# exec(open('gan_discriminator_tf.py').read())\n",
    "\n",
    "# Train\n",
    "# train_gan(generator, discriminator, x_train, epochs=10000, batch_size=128)\n",
    "\n",
    "print(\"To train the GAN, uncomment and run the code above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random latent vectors\n",
    "# latent_dim = 100\n",
    "# noise = np.random.normal(0, 1, (25, latent_dim))\n",
    "\n",
    "# Generate images\n",
    "# generated_images = generator.predict(noise)\n",
    "# generated_images = (generated_images + 1) / 2.0  # Rescale to [0, 1]\n",
    "\n",
    "# Display\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(25):\n",
    "#     plt.subplot(5, 5, i + 1)\n",
    "#     plt.imshow(generated_images[i].squeeze(), cmap='gray')\n",
    "#     plt.axis('off')\n",
    "# plt.suptitle('Generated MNIST Digits')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "print(\"Image generation code ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation in Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_latent_space(generator, n_steps=10, latent_dim=100):\n",
    "    \"\"\"\n",
    "    Generate interpolated images between two random points\n",
    "    \"\"\"\n",
    "    # Generate two random points\n",
    "    # start_point = np.random.normal(0, 1, (1, latent_dim))\n",
    "    # end_point = np.random.normal(0, 1, (1, latent_dim))\n",
    "    \n",
    "    # Interpolate\n",
    "    # ratios = np.linspace(0, 1, n_steps)\n",
    "    # interpolated_points = []\n",
    "    # for ratio in ratios:\n",
    "    #     point = start_point * (1 - ratio) + end_point * ratio\n",
    "    #     interpolated_points.append(point)\n",
    "    \n",
    "    # Generate images\n",
    "    # interpolated_points = np.vstack(interpolated_points)\n",
    "    # interpolated_images = generator.predict(interpolated_points)\n",
    "    # interpolated_images = (interpolated_images + 1) / 2.0\n",
    "    \n",
    "    # Display\n",
    "    # plt.figure(figsize=(20, 2))\n",
    "    # for i in range(n_steps):\n",
    "    #     plt.subplot(1, n_steps, i + 1)\n",
    "    #     plt.imshow(interpolated_images[i].squeeze(), cmap='gray')\n",
    "    #     plt.axis('off')\n",
    "    # plt.suptitle('Latent Space Interpolation')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "# interpolate_latent_space(generator, n_steps=10)\n",
    "\n",
    "print(\"Latent space interpolation function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate GAN Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common metrics for GAN evaluation:\n",
    "# - Inception Score (IS)\n",
    "# - Frechet Inception Distance (FID)\n",
    "# - Discriminator accuracy\n",
    "# - Visual inspection\n",
    "\n",
    "def plot_training_history(d_losses, g_losses):\n",
    "    \"\"\"\n",
    "    Plot discriminator and generator losses\n",
    "    \"\"\"\n",
    "    # plt.figure(figsize=(12, 5))\n",
    "    # \n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.plot(d_losses, label='Discriminator Loss')\n",
    "    # plt.xlabel('Iteration')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.title('Discriminator Loss')\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # \n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.plot(g_losses, label='Generator Loss', color='orange')\n",
    "    # plt.xlabel('Iteration')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.title('Generator Loss')\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # \n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    pass\n",
    "\n",
    "print(\"Training history visualization ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced GAN Variants\n",
    "\n",
    "Consider exploring:\n",
    "- **DCGAN**: Deep Convolutional GAN\n",
    "- **WGAN**: Wasserstein GAN with improved training stability\n",
    "- **StyleGAN**: High-quality image generation\n",
    "- **CycleGAN**: Image-to-image translation\n",
    "- **Conditional GAN**: Controlled generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we:\n",
    "1. Built Generator and Discriminator networks\n",
    "2. Understood adversarial training\n",
    "3. Generated new images from random noise\n",
    "4. Explored latent space interpolation\n",
    "\n",
    "## Next Steps\n",
    "- Implement DCGAN with convolutional layers\n",
    "- Try Wasserstein loss for stability\n",
    "- Build conditional GANs\n",
    "- Explore StyleGAN for high-quality generation\n",
    "- Apply to other domains (audio, text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
