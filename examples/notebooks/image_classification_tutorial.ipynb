{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with Neural DSL\n",
    "\n",
    "This tutorial demonstrates how to build a complete image classification pipeline using Neural DSL.\n",
    "\n",
    "## Overview\n",
    "- Build a CNN for image classification\n",
    "- Train on CIFAR-10 or custom datasets\n",
    "- Visualize model architecture and performance\n",
    "- Export and deploy the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Neural DSL if not already installed\n",
    "# !pip install neural-dsl\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import neural CLI programmatically\n",
    "from neural.cli.cli import cli\n",
    "from neural.parser.parser import create_parser, ModelTransformer\n",
    "from neural.code_generation.code_generator import generate_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model in Neural DSL\n",
    "\n",
    "We'll create a convolutional neural network for image classification with:\n",
    "- Multiple convolutional blocks with batch normalization\n",
    "- Max pooling and dropout for regularization\n",
    "- Dense layers for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsl_code = \"\"\"\n",
    "network ImageClassifier {\n",
    "  input: (None, 32, 32, 3)\n",
    "  \n",
    "  layers:\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding=\"same\")\n",
    "    BatchNormalization()\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding=\"same\")\n",
    "    BatchNormalization()\n",
    "    MaxPooling2D(pool_size=(2,2))\n",
    "    Dropout(rate=0.25)\n",
    "    \n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\")\n",
    "    BatchNormalization()\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\")\n",
    "    BatchNormalization()\n",
    "    MaxPooling2D(pool_size=(2,2))\n",
    "    Dropout(rate=0.25)\n",
    "    \n",
    "    Flatten()\n",
    "    Dense(units=256, activation=\"relu\")\n",
    "    BatchNormalization()\n",
    "    Dropout(rate=0.5)\n",
    "    Output(units=10, activation=\"softmax\")\n",
    "\n",
    "  loss: \"categorical_crossentropy\"\n",
    "  optimizer: Adam(learning_rate=0.001)\n",
    "  metrics: [\"accuracy\"]\n",
    "\n",
    "  train {\n",
    "    epochs: 50\n",
    "    batch_size: 64\n",
    "    validation_split: 0.2\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Save the DSL code to a file\n",
    "with open('image_classifier.neural', 'w') as f:\n",
    "    f.write(dsl_code)\n",
    "\n",
    "print(\"Model defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model\n",
    "\n",
    "Use Neural CLI to compile the DSL to TensorFlow or PyTorch code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile to TensorFlow\n",
    "!neural compile image_classifier.neural --backend tensorflow --output image_classifier_tf.py\n",
    "\n",
    "print(\"\\nModel compiled to TensorFlow!\")\n",
    "print(\"Output file: image_classifier_tf.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model\n",
    "!neural visualize image_classifier.neural --format html\n",
    "\n",
    "print(\"Visualization generated!\")\n",
    "print(\"Open architecture.svg to see the model structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "We'll use CIFAR-10 dataset for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 data\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    \n",
    "    # Load dataset\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "    \n",
    "    # Convert labels to categorical\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    print(f\"Training data shape: {x_train.shape}\")\n",
    "    print(f\"Test data shape: {x_test.shape}\")\n",
    "    \n",
    "    # Display sample images\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(x_train[i])\n",
    "        plt.xlabel(class_names[np.argmax(y_train[i])])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"TensorFlow not installed. Install with: pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the generated model code\n",
    "try:\n",
    "    exec(open('image_classifier_tf.py').read())\n",
    "    \n",
    "    # Note: The generated code should create and compile the model\n",
    "    # You may need to adapt this based on the actual generated code structure\n",
    "    \n",
    "    print(\"Model loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"You may need to run the generated script manually\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Use CLI to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using Neural CLI\n",
    "!neural run image_classifier_tf.py --backend tensorflow --dataset CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell assumes the model has been trained and is available\n",
    "# Adapt based on your actual training results\n",
    "\n",
    "# Example evaluation (pseudo-code)\n",
    "# test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "# print(f'\\nTest accuracy: {test_acc:.4f}')\n",
    "# print(f'Test loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test images\n",
    "# predictions = model.predict(x_test[:10])\n",
    "\n",
    "# # Visualize predictions\n",
    "# plt.figure(figsize=(15, 3))\n",
    "# for i in range(10):\n",
    "#     plt.subplot(2, 5, i + 1)\n",
    "#     plt.imshow(x_test[i])\n",
    "#     predicted_class = class_names[np.argmax(predictions[i])]\n",
    "#     true_class = class_names[np.argmax(y_test[i])]\n",
    "#     color = 'green' if predicted_class == true_class else 'red'\n",
    "#     plt.xlabel(f'Pred: {predicted_class}\\nTrue: {true_class}', color=color)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Neural's HPO feature\n",
    "!neural compile image_classifier.neural --backend tensorflow --hpo --dataset CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug with NeuralDbg dashboard\n",
    "# Run this in a separate terminal:\n",
    "# neural debug image_classifier.neural --backend tensorflow --dashboard --port 8050\n",
    "\n",
    "print(\"To debug the model, run:\")\n",
    "print(\"neural debug image_classifier.neural --backend tensorflow --dashboard --port 8050\")\n",
    "print(\"Then visit http://localhost:8050 in your browser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model\n",
    "\n",
    "Export to different formats for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile to PyTorch\n",
    "!neural compile image_classifier.neural --backend pytorch --output image_classifier_torch.py\n",
    "\n",
    "# Compile to ONNX\n",
    "!neural compile image_classifier.neural --backend onnx --output image_classifier.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we:\n",
    "1. Defined an image classification model using Neural DSL\n",
    "2. Compiled it to TensorFlow code\n",
    "3. Visualized the model architecture\n",
    "4. Trained on CIFAR-10 dataset\n",
    "5. Evaluated and made predictions\n",
    "6. Explored hyperparameter optimization\n",
    "7. Learned about debugging tools\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try different architectures (ResNet, VGG, MobileNet)\n",
    "- Use transfer learning with pre-trained models\n",
    "- Implement data augmentation\n",
    "- Deploy the model to production\n",
    "- Explore other use cases (NLP, time series, GANs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
