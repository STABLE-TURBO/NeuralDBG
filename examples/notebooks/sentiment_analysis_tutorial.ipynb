{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Neural DSL\n",
    "\n",
    "This tutorial demonstrates how to build a sentiment analysis model using Neural DSL and LSTMs.\n",
    "\n",
    "## Overview\n",
    "- Build an LSTM-based sentiment classifier\n",
    "- Process text data with embeddings\n",
    "- Train on movie reviews (IMDB dataset)\n",
    "- Evaluate and interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neural.parser.parser import create_parser, ModelTransformer\n",
    "from neural.code_generation.code_generator import generate_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsl_code = \"\"\"\n",
    "network SentimentAnalyzer {\n",
    "  input: (None, 200)\n",
    "  \n",
    "  layers:\n",
    "    Embedding(input_dim=20000, output_dim=128)\n",
    "    Dropout(rate=0.2)\n",
    "    LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "    LSTM(units=64, dropout=0.2, recurrent_dropout=0.2)\n",
    "    Dense(units=64, activation=\"relu\")\n",
    "    Dropout(rate=0.5)\n",
    "    Dense(units=32, activation=\"relu\")\n",
    "    Dropout(rate=0.5)\n",
    "    Output(units=1, activation=\"sigmoid\")\n",
    "\n",
    "  loss: \"binary_crossentropy\"\n",
    "  optimizer: Adam(learning_rate=0.001)\n",
    "  metrics: [\"accuracy\"]\n",
    "\n",
    "  train {\n",
    "    epochs: 10\n",
    "    batch_size: 128\n",
    "    validation_split: 0.2\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open('sentiment_analyzer.neural', 'w') as f:\n",
    "    f.write(dsl_code)\n",
    "\n",
    "print(\"Sentiment analysis model defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!neural compile sentiment_analyzer.neural --backend tensorflow --output sentiment_analyzer_tf.py\n",
    "print(\"Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare IMDB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras.preprocessing import sequence\n",
    "    \n",
    "    # Load IMDB dataset\n",
    "    max_features = 20000\n",
    "    maxlen = 200\n",
    "    \n",
    "    print(\"Loading IMDB dataset...\")\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(\n",
    "        num_words=max_features\n",
    "    )\n",
    "    \n",
    "    print(f\"Training sequences: {len(x_train)}\")\n",
    "    print(f\"Test sequences: {len(x_test)}\")\n",
    "    \n",
    "    # Pad sequences\n",
    "    print(\"Padding sequences...\")\n",
    "    x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "    x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "    \n",
    "    print(f\"x_train shape: {x_train.shape}\")\n",
    "    print(f\"x_test shape: {x_test.shape}\")\n",
    "    \n",
    "    # Display distribution\n",
    "    print(f\"\\nPositive samples in training: {np.sum(y_train)} ({np.mean(y_train)*100:.1f}%)\")\n",
    "    print(f\"Negative samples in training: {len(y_train) - np.sum(y_train)} ({(1-np.mean(y_train))*100:.1f}%)\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"TensorFlow not installed. Install with: pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Sample Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get word index\n",
    "    word_index = keras.datasets.imdb.get_word_index()\n",
    "    reverse_word_index = {v: k for k, v in word_index.items()}\n",
    "    \n",
    "    def decode_review(encoded_review):\n",
    "        return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
    "    \n",
    "    # Display a few reviews\n",
    "    for i in range(3):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Review {i+1} - Sentiment: {'Positive' if y_train[i] == 1 else 'Negative'}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(decode_review(x_train[i])[:500])\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error displaying reviews: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!neural visualize sentiment_analyzer.neural --format html\n",
    "print(\"Visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use generated code\n",
    "# exec(open('sentiment_analyzer_tf.py').read())\n",
    "\n",
    "# Option 2: Use CLI\n",
    "!neural run sentiment_analyzer_tf.py --backend tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example evaluation (adapt based on your training)\n",
    "# test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "# print(f'\\nTest accuracy: {test_acc:.4f}')\n",
    "# print(f'Test loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict(x_test[:10])\n",
    "\n",
    "# for i in range(10):\n",
    "#     sentiment = \"Positive\" if predictions[i] > 0.5 else \"Negative\"\n",
    "#     actual = \"Positive\" if y_test[i] == 1 else \"Negative\"\n",
    "#     confidence = predictions[i][0] if predictions[i] > 0.5 else 1 - predictions[i][0]\n",
    "#     \n",
    "#     print(f\"\\nReview {i+1}:\")\n",
    "#     print(f\"Predicted: {sentiment} ({confidence:.2%} confidence)\")\n",
    "#     print(f\"Actual: {actual}\")\n",
    "#     print(decode_review(x_test[i])[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Custom Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review_text, model, max_features=20000, maxlen=200):\n",
    "    # Tokenize and encode\n",
    "    tokens = review_text.lower().split()\n",
    "    encoded = [word_index.get(word, 0) for word in tokens]\n",
    "    padded = sequence.pad_sequences([encoded], maxlen=maxlen)\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(padded)[0][0]\n",
    "    sentiment = \"Positive\" if prediction > 0.5 else \"Negative\"\n",
    "    confidence = prediction if prediction > 0.5 else 1 - prediction\n",
    "    \n",
    "    return sentiment, confidence\n",
    "\n",
    "# Test with custom reviews\n",
    "test_reviews = [\n",
    "    \"This movie was absolutely fantastic! I loved every minute of it.\",\n",
    "    \"Terrible waste of time. The plot was confusing and the acting was poor.\",\n",
    "    \"It was okay, nothing special but not terrible either.\"\n",
    "]\n",
    "\n",
    "# for review in test_reviews:\n",
    "#     sentiment, confidence = predict_sentiment(review, model)\n",
    "#     print(f\"\\nReview: {review}\")\n",
    "#     print(f\"Sentiment: {sentiment} ({confidence:.2%} confidence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!neural compile sentiment_analyzer.neural --backend tensorflow --hpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug with NeuralDbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"To debug, run in terminal:\")\n",
    "print(\"neural debug sentiment_analyzer.neural --backend tensorflow --dashboard --port 8050\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we:\n",
    "1. Built an LSTM-based sentiment classifier\n",
    "2. Processed text data with embeddings\n",
    "3. Trained on IMDB movie reviews\n",
    "4. Made predictions on custom text\n",
    "\n",
    "## Next Steps\n",
    "- Try bidirectional LSTMs\n",
    "- Experiment with GRU layers\n",
    "- Use pre-trained word embeddings (Word2Vec, GloVe)\n",
    "- Build multi-class sentiment classifiers\n",
    "- Explore attention mechanisms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
