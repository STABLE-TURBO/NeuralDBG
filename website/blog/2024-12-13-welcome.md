---
slug: welcome
title: Welcome to Neural DSL
authors: [neural-team]
tags: [announcement, getting-started]
---

# Welcome to Neural DSL!

We're excited to launch the official Neural DSL website and documentation portal!

Neural DSL is a modern neural network programming language that simplifies deep learning development with:

- **Clean, declarative syntax** - Write models without framework boilerplate
- **Cross-framework support** - Compile to TensorFlow, PyTorch, or ONNX
- **Built-in debugging** - NeuralDbg with real-time tracing
- **Shape validation** - Catch errors before runtime

<!--truncate-->

## What Makes Neural DSL Different?

Traditional deep learning frameworks require you to learn their specific APIs and deal with lots of boilerplate code. Neural DSL provides a unified, clean syntax that compiles to any framework you need.

### Before (TensorFlow):

```python
import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

### After (Neural DSL):

```yaml
network MNISTClassifier {
  input: (28, 28, 1)
  
  layers:
    Conv2D(32, (3,3), "relu")
    MaxPooling2D((2,2))
    Flatten()
    Dense(128, "relu")
    Dropout(0.5)
    Output(10, "softmax")
  
  loss: "sparse_categorical_crossentropy"
  optimizer: Adam(learning_rate=0.001)
}
```

Much cleaner, right? And you can compile this to TensorFlow, PyTorch, or ONNX with a single flag!

## Key Features

### ðŸŽ¯ Simple & Intuitive
Write neural networks in a clean, YAML-like syntax. No framework boilerplate needed.

### ðŸ”„ Cross-Framework
Switch between TensorFlow, PyTorch, and ONNX without rewriting code.

### âœ… Shape Validation
Automatic shape propagation catches errors before runtime.

### ðŸ› Built-in Debugger
NeuralDbg provides real-time execution tracing and gradient analysis.

## Getting Started

Ready to try it out? Here's how to get started:

```bash
# Install
pip install neural-dsl[full]

# Create a model
echo 'network MyModel { ... }' > model.neural

# Compile to TensorFlow
neural compile model.neural --backend tensorflow

# Or PyTorch
neural compile model.neural --backend pytorch

# Or run directly
neural run model.neural --backend tensorflow
```

Check out our [Quick Start Guide](/docs/getting-started/quick-start) for a complete walkthrough.

## Try the Playground

Want to experiment without installing anything? Try our [Interactive Playground](/playground) - write DSL code and see it compiled to different backends in real-time!

## Community

Join our growing community:

- [Discord](https://discord.gg/KFku4KvS) - Chat with developers and get help
- [GitHub](https://github.com/Lemniscate-world/Neural) - Source code and issues
- [Twitter](https://x.com/NLang4438) - Latest updates and news

## What's Next?

We're actively working on:
- Enhanced HPO features
- More visualization tools
- Additional backend support
- Improved documentation
- More examples and tutorials

Stay tuned for more updates! ðŸš€

## Feedback

We'd love to hear what you think! Share your feedback:
- [Discord community](https://discord.gg/KFku4KvS)
- [GitHub discussions](https://github.com/Lemniscate-world/Neural/discussions)
- [Feedback form](https://form.typeform.com/to/xcibBdKD)

Let's build the future of neural network development together!
