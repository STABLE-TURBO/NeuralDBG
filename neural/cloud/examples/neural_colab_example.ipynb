{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural DSL on Google Colab\n",
    "\n",
    "This notebook demonstrates how to use Neural DSL in Google Colab environments.\n",
    "\n",
    "## 1. Installation\n",
    "\n",
    "First, we need to install Neural DSL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install Neural DSL\n",
    "!pip install git+https://github.com/Lemniscate-SHA-256/Neural.git\n",
    "\n",
    "# Install pyngrok for tunneling\n",
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check GPU Availability\n",
    "\n",
    "Let's check if we have a GPU available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Neural Cloud Module\n",
    "\n",
    "Now we can import the Neural cloud module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from neural.cloud.cloud_execution import CloudExecutor\n",
    "\n",
    "# Initialize the cloud executor\n",
    "executor = CloudExecutor()\n",
    "print(f\"Detected environment: {executor.environment}\")\n",
    "print(f\"GPU available: {executor.is_gpu_available}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define a Neural DSL Model\n",
    "\n",
    "Let's define a simple CNN model for CIFAR-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "dsl_code = \"\"\"\n",
    "network Cifar10CNN {\n",
    "    input: (32, 32, 3)\n",
    "    layers:\n",
    "        Conv2D(32, (3, 3), \"relu\", padding=\"same\")\n",
    "        Conv2D(32, (3, 3), \"relu\")\n",
    "        MaxPooling2D((2, 2))\n",
    "        Dropout(0.25)\n",
    "        \n",
    "        Conv2D(64, (3, 3), \"relu\", padding=\"same\")\n",
    "        Conv2D(64, (3, 3), \"relu\")\n",
    "        MaxPooling2D((2, 2))\n",
    "        Dropout(0.25)\n",
    "        \n",
    "        Flatten()\n",
    "        Dense(512, \"relu\")\n",
    "        Dropout(0.5)\n",
    "        Dense(10, \"softmax\")\n",
    "    loss: \"categorical_crossentropy\"\n",
    "    optimizer: Adam(learning_rate=0.001)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(dsl_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compile the Model\n",
    "\n",
    "Now we can compile the model to PyTorch code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compile to PyTorch\n",
    "pt_model_path = executor.compile_model(dsl_code, backend='pytorch')\n",
    "print(f\"Model compiled to: {pt_model_path}\")\n",
    "\n",
    "# Display the generated code\n",
    "with open(pt_model_path, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run the Model\n",
    "\n",
    "Let's run the compiled model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run the model\n",
    "results = executor.run_model(pt_model_path, dataset='CIFAR10', epochs=5, batch_size=128)\n",
    "\n",
    "if results['success']:\n",
    "    print(\"Model execution successful!\")\n",
    "else:\n",
    "    print(f\"Model execution failed: {results['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize the Model\n",
    "\n",
    "We can also visualize the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize the model\n",
    "viz_path = executor.visualize_model(dsl_code, output_format='png')\n",
    "\n",
    "# Display the visualization\n",
    "from IPython.display import Image\n",
    "Image(filename=viz_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Start the NeuralDbg Dashboard\n",
    "\n",
    "We can also start the NeuralDbg dashboard with an ngrok tunnel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Start the dashboard\n",
    "dashboard_info = executor.start_debug_dashboard(dsl_code, backend='pytorch', setup_tunnel=True)\n",
    "\n",
    "print(f\"Dashboard URL: {dashboard_info['dashboard_url']}\")\n",
    "print(f\"Tunnel URL: {dashboard_info['tunnel_url']}\")\n",
    "\n",
    "# Display a clickable link\n",
    "from IPython.display import HTML\n",
    "HTML(f\"<a href='{dashboard_info['tunnel_url']}' target='_blank'>Open NeuralDbg Dashboard</a>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Start the No-Code Interface\n",
    "\n",
    "Finally, we can start the Neural No-Code interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Start the No-Code interface\n",
    "nocode_info = executor.start_nocode_interface(setup_tunnel=True)\n",
    "\n",
    "print(f\"No-Code Interface URL: {nocode_info['interface_url']}\")\n",
    "print(f\"Tunnel URL: {nocode_info['tunnel_url']}\")\n",
    "\n",
    "# Display a clickable link\n",
    "from IPython.display import HTML\n",
    "HTML(f\"<a href='{nocode_info['tunnel_url']}' target='_blank'>Open Neural No-Code Interface</a>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Advanced: HPO in Colab\n",
    "\n",
    "Let's try hyperparameter optimization in Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define a model with HPO\n",
    "hpo_dsl_code = \"\"\"\n",
    "network Cifar10HPO {\n",
    "    input: (32, 32, 3)\n",
    "    layers:\n",
    "        Conv2D(HPO(choice(32, 64, 128)), (3, 3), \"relu\", padding=\"same\")\n",
    "        MaxPooling2D((2, 2))\n",
    "        Dropout(HPO(range(0.1, 0.5, step=0.1)))\n",
    "        \n",
    "        Conv2D(64, (3, 3), \"relu\")\n",
    "        MaxPooling2D((2, 2))\n",
    "        \n",
    "        Flatten()\n",
    "        Dense(HPO(choice(128, 256, 512)), \"relu\")\n",
    "        Dropout(0.5)\n",
    "        Dense(10, \"softmax\")\n",
    "    loss: \"categorical_crossentropy\"\n",
    "    optimizer: Adam(learning_rate=HPO(log_range(0.0001, 0.01)))\n",
    "    train {\n",
    "        epochs: 5\n",
    "        batch_size: HPO(choice(32, 64, 128))\n",
    "        search_method: \"bayesian\"\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Compile with HPO\n",
    "hpo_model_path = executor.compile_model(hpo_dsl_code, backend='tensorflow')\n",
    "print(f\"HPO model compiled to: {hpo_model_path}\")\n",
    "\n",
    "# Run HPO\n",
    "hpo_results = executor.run_model(hpo_model_path, dataset='CIFAR10')\n",
    "\n",
    "if hpo_results['success']:\n",
    "    print(\"HPO execution successful!\")\n",
    "else:\n",
    "    print(f\"HPO execution failed: {hpo_results['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cleanup\n",
    "\n",
    "When you're done, you can clean up the temporary files and processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clean up\n",
    "executor.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
