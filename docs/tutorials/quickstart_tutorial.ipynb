{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural DSL Quick Start Tutorial\n",
    "\n",
    "Welcome to Neural DSL! This tutorial will guide you through:\n",
    "1. Installing Neural DSL\n",
    "2. Creating your first model\n",
    "3. Compiling and running the model\n",
    "4. Visualizing the architecture\n",
    "5. Debugging with NeuralDbg\n",
    "\n",
    "**Time to complete:** ~15 minutes\n",
    "\n",
    "**Prerequisites:**\n",
    "- Python 3.8+\n",
    "- Basic understanding of neural networks\n",
    "- pip package manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installation\n",
    "\n",
    "First, let's install Neural DSL. We'll install with TensorFlow backend for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Neural DSL with TensorFlow\n",
    "!pip install neural-dsl tensorflow\n",
    "\n",
    "# Verify installation\n",
    "import neural\n",
    "print(f\"Neural DSL version: {neural.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Your First Model\n",
    "\n",
    "Let's create a simple neural network for MNIST digit classification.\n",
    "\n",
    "We'll write the model in Neural DSL syntax and save it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model in Neural DSL\n",
    "dsl_code = \"\"\"\n",
    "network SimpleClassifier {\n",
    "  # Input: 28x28 grayscale images (MNIST)\n",
    "  input: (28, 28, 1)\n",
    "  \n",
    "  layers:\n",
    "    # Convolutional feature extraction\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")\n",
    "    MaxPooling2D(pool_size=(2, 2))\n",
    "    \n",
    "    # Flatten and classify\n",
    "    Flatten()\n",
    "    Dense(units=128, activation=\"relu\")\n",
    "    Dropout(rate=0.5)\n",
    "    Output(units=10, activation=\"softmax\")\n",
    "  \n",
    "  # Training configuration\n",
    "  loss: \"sparse_categorical_crossentropy\"\n",
    "  optimizer: Adam(learning_rate=0.001)\n",
    "  metrics: [\"accuracy\"]\n",
    "  \n",
    "  train {\n",
    "    epochs: 10\n",
    "    batch_size: 64\n",
    "    validation_split: 0.2\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Save to file\n",
    "with open('my_first_model.neural', 'w') as f:\n",
    "    f.write(dsl_code)\n",
    "\n",
    "print(\"âœ… Model definition saved to 'my_first_model.neural'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the DSL Syntax\n",
    "\n",
    "Let's break down what each part means:\n",
    "\n",
    "- **`network SimpleClassifier { ... }`**: Defines a neural network named SimpleClassifier\n",
    "- **`input: (28, 28, 1)`**: Specifies input shape (height, width, channels)\n",
    "- **`layers:`**: Lists all layers in sequential order\n",
    "- **`Conv2D(filters=32, ...)`**: Convolutional layer with 32 filters\n",
    "- **`Output(units=10, ...)`**: Final layer with 10 classes\n",
    "- **`loss:`**: Loss function for training\n",
    "- **`optimizer:`**: Optimization algorithm\n",
    "- **`train { ... }`**: Training configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compile the Model\n",
    "\n",
    "Neural DSL can generate code for different backends. Let's compile to TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile DSL to TensorFlow\n",
    "!neural compile my_first_model.neural --backend tensorflow --output simple_model_tf.py\n",
    "\n",
    "print(\"\\nâœ… Model compiled successfully!\")\n",
    "print(\"Generated file: simple_model_tf.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a snippet of the generated code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and display first 30 lines of generated code\n",
    "with open('simple_model_tf.py', 'r') as f:\n",
    "    lines = f.readlines()[:30]\n",
    "    print(''.join(lines))\n",
    "    print(\"\\n... (truncated) ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load and Prepare Data\n",
    "\n",
    "Before training, let's load the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess data\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "print(f\"Training samples: {x_train.shape[0]}\")\n",
    "print(f\"Test samples: {x_test.shape[0]}\")\n",
    "print(f\"Input shape: {x_train.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some sample images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display first 10 images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(x_train[i].reshape(28, 28), cmap='gray')\n",
    "    ax.set_title(f\"Label: {y_train[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model\n",
    "\n",
    "Now let's import and train the generated model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the generated model code\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "from simple_model_tf import create_model\n",
    "\n",
    "# Create and compile model\n",
    "model = create_model()\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (just 3 epochs for demo)\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=3,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate and Visualize Results\n",
    "\n",
    "Let's evaluate the model and visualize training progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot loss\n",
    "ax2.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Make Predictions\n",
    "\n",
    "Let's test our model on some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "predictions = model.predict(x_test[:10])\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    true_label = y_test[i]\n",
    "    pred_label = predicted_classes[i]\n",
    "    confidence = predictions[i][pred_label]\n",
    "    \n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    ax.set_title(f\"True: {true_label}\\nPred: {pred_label} ({confidence:.2%})\", \n",
    "                 color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Model Architecture\n",
    "\n",
    "Neural DSL can generate architecture diagrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate architecture visualization\n",
    "!neural visualize my_first_model.neural --format png\n",
    "\n",
    "print(\"âœ… Architecture diagrams generated!\")\n",
    "print(\"Files: architecture.png, shape_propagation.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Switching Backends\n",
    "\n",
    "One of Neural DSL's key features is easy backend switching. Let's compile to PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile same model to PyTorch\n",
    "!neural compile my_first_model.neural --backend pytorch --output simple_model_torch.py\n",
    "\n",
    "print(\"\\nâœ… PyTorch version compiled!\")\n",
    "print(\"\\nThe SAME model definition generated code for both TensorFlow and PyTorch!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Debugging with NeuralDbg (Optional)\n",
    "\n",
    "Neural DSL includes a powerful debugging dashboard. To use it:\n",
    "\n",
    "```bash\n",
    "# In terminal, run:\n",
    "neural debug my_first_model.neural\n",
    "\n",
    "# Then open browser to: http://localhost:8050\n",
    "```\n",
    "\n",
    "Features:\n",
    "- Real-time execution tracing\n",
    "- Gradient flow visualization\n",
    "- Dead neuron detection\n",
    "- Anomaly detection\n",
    "- Memory and FLOP profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've completed the Neural DSL quickstart tutorial. You learned:\n",
    "\n",
    "âœ… How to install Neural DSL  \n",
    "âœ… How to write models in DSL syntax  \n",
    "âœ… How to compile to different backends  \n",
    "âœ… How to train and evaluate models  \n",
    "âœ… How to visualize architectures  \n",
    "âœ… How to switch between TensorFlow and PyTorch  \n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue learning with these tutorials:\n",
    "\n",
    "1. **[Hyperparameter Optimization Tutorial](hpo_tutorial.ipynb)** - Learn to optimize your models\n",
    "2. **[Advanced Architectures Tutorial](advanced_architectures.ipynb)** - Build complex models\n",
    "3. **[Cloud Integration Tutorial](cloud_tutorial.ipynb)** - Run on Kaggle, Colab, AWS\n",
    "4. **[Debugging Tutorial](debugging_tutorial.ipynb)** - Master NeuralDbg\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **Documentation:** [docs/](../../docs/)\n",
    "- **Examples:** [examples/](../../examples/)\n",
    "- **Discord:** [Join our community](https://discord.gg/KFku4KvS)\n",
    "- **GitHub:** [Issues & Discussions](https://github.com/Lemniscate-world/Neural)\n",
    "\n",
    "Happy modeling! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
